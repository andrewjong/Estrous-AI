{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show more than one output in cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models as tvm\n",
    "import pretrainedmodels as ptm\n",
    "models = (\n",
    "#     ptm.alexnet, # gets maximum recursion limit exceeded exceptions\n",
    "    ptm.nasnetalarge, # calculated output size is too small\n",
    "#     ptm.se_resnet50,\n",
    "#     ptm.se_resnet101,\n",
    "#     ptm.inceptionresnetv2,\n",
    "#     ptm.inceptionv4,\n",
    "#     ptm.vgg16,\n",
    "#     ptm.vgg19,\n",
    "#     tvm.resnet101,\n",
    "#     ptm.senet154,\n",
    ")\n",
    "\n",
    "DATA_DIR = 'data/4_class_11'\n",
    "\n",
    "domain = [\n",
    "#     {'name': 'model_num', 'type': 'discrete', 'domain': range(len(models))},\n",
    "    {'name': 'batch_size', 'type': 'discrete', 'domain': (16, 24, 32, 48, 64)},\n",
    "    {'name': 'adam_lr', 'type': 'continuous', 'domain': (0.001, 0.1)},\n",
    "    {'name': 'adam_beta1', 'type': 'continuous', 'domain': (0.8, .99)},\n",
    "    {'name': 'adam_beta2', 'type': 'continuous', 'domain': (0.95, .9999)},\n",
    "    {'name': 'adam_wtdecay', 'type': 'continuous', 'domain': (0, 1)},\n",
    "    {'name': 'epochs', 'type': 'discrete', 'domain': (10, 20, 30, 40)}\n",
    "]\n",
    "#default_input = [3, 32, 0.001, 0.9, 0.999, 0, 30] # TODO: have to figure out how to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import src.utils as utils\n",
    "\n",
    "model_num = 0\n",
    "\n",
    "def f(x):\n",
    "    \"\"\" Value function to minimize for bayesian optimization \"\"\"\n",
    "    val_acc = train(\n",
    "        model_num,\n",
    "        batch_size=int(x[:,0]),\n",
    "        adam_lr=float(x[:,1]),\n",
    "        adam_b1=float(x[:,2]),\n",
    "        adam_b2=float(x[:,3]),\n",
    "        adam_wtdecay=float(x[:,4]),\n",
    "        epochs=int(x[:,5])\n",
    "    )\n",
    "    \n",
    "    return -val_acc\n",
    "\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "\n",
    "def prepare_model(model_num):\n",
    "    model_fn = models[model_num]\n",
    "    if model_fn is tvm.resnet101:\n",
    "        # torchvision models\n",
    "        pretrained = True\n",
    "        last = 'fc'\n",
    "    else:\n",
    "        # pretrainedmodels package specific differences\n",
    "        pretrained = 'imagenet'\n",
    "        last = 'last_linear'\n",
    "    image_size = utils.determine_image_size(model_name_from_num(model_num))\n",
    "    \n",
    "    model = model_fn(num_classes=1000, pretrained=pretrained)\n",
    "    num_in = getattr(model, last).in_features\n",
    "    setattr(model, last, torch.nn.Linear(num_in, NUM_CLASSES))\n",
    "    return model, image_size\n",
    "\n",
    "def model_name_from_num(model_num):\n",
    "    return str(models[model_num]).split()[1]\n",
    "\n",
    "\n",
    "import os\n",
    "from train import prepare_results_file\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import  CrossEntropyLoss\n",
    "from src.trainable import Trainable\n",
    "from src.utils import get_datasets_and_loaders\n",
    "\n",
    "iteration = 0\n",
    "def train(model_num, batch_size, adam_lr, adam_b1, adam_b2, adam_wtdecay, epochs):\n",
    "    global iteration\n",
    "    iteration += 1\n",
    "    print(\"\\nITERATION\", iteration)\n",
    "    print(f'model: {str(models[model_num]).split()[1]}, batch_size: {batch_size}, epochs: {epochs}')\n",
    "    print(f'adam_lr: {adam_lr}, adam_b1: {adam_b1}, adam_b2: {adam_b2}, adam_wtdecay: {adam_wtdecay}')\n",
    "\n",
    "    model, image_size = prepare_model(model_num)\n",
    "    \n",
    "    _, dataloaders = get_datasets_and_loaders(DATA_DIR, 'train', 'val', \n",
    "                                              image_size=image_size)\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), adam_lr, (adam_b1, adam_b2), adam_wtdecay)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    \n",
    "    trainable = Trainable(model, criterion, optimizer)\n",
    "    \n",
    "    params = '_'.join([str(batch_size)] + [f'{param:4f}' for param in (adam_lr, adam_b1, adam_b2, adam_wtdecay)] + [str(epochs)])\n",
    "    results_fp = os.path.join(\"experiments\", \"bayes_opt\", model_name_from_num(model_num), os.path.basename(DATA_DIR), params + '.csv')\n",
    "\n",
    "    prepare_results_file(results_fp)\n",
    "    try:\n",
    "        val_acc = trainable.train(dataloaders, epochs, early_stop=5, results_filepath=results_fp, verbose=False)\n",
    "    except Exception as e:\n",
    "        if iteration > 1:\n",
    "            raise e\n",
    "        print(e)\n",
    "        val_acc = 0\n",
    "    return val_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # TEST CODE\n",
    "# train(model, 4, 1e-3, 0.9, 0.999, 0, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do BO on all models on both datasets. Git push at each stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA/DIE_VS_ALL_11\n",
      "\n",
      "ITERATION 1\n",
      "model: nasnetalarge, batch_size: 64, epochs: 40\n",
      "adam_lr: 0.08685243254841131, adam_b1: 0.823704459660309, adam_b2: 0.9897171846605224, adam_wtdecay: 0.3675735165519015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 10 epochs.\n",
      "Training completed in 23m 15s\n",
      "Best validation accuracy: 0.8726\n",
      "Associated train accuracy: 0.8026\n",
      "Associated train loss: 0.4322\n",
      "\n",
      "ITERATION 2\n",
      "model: nasnetalarge, batch_size: 16, epochs: 30\n",
      "adam_lr: 0.07624192331977708, adam_b1: 0.8541326644005715, adam_b2: 0.9780713437887167, adam_wtdecay: 0.8451001186921837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 10 epochs.\n",
      "Training completed in 23m 16s\n",
      "Best validation accuracy: 0.9057\n",
      "Associated train accuracy: 0.8715\n",
      "Associated train loss: 0.2915\n",
      "\n",
      "ITERATION 3\n",
      "model: nasnetalarge, batch_size: 32, epochs: 10\n",
      "adam_lr: 0.09868876358102838, adam_b1: 0.827961682855212, adam_b2: 0.97942299782448, adam_wtdecay: 0.694030065570928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 10 epochs.\n",
      "Training completed in 23m 16s\n",
      "Best validation accuracy: 0.9057\n",
      "Associated train accuracy: 0.8573\n",
      "Associated train loss: 0.3566\n",
      "\n",
      "ITERATION 4\n",
      "model: nasnetalarge, batch_size: 24, epochs: 10\n",
      "adam_lr: 0.04736740684090222, adam_b1: 0.8774121931335087, adam_b2: 0.9951958112366829, adam_wtdecay: 0.14396959250530872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 9 epochs.\n",
      "Training completed in 20m 57s\n",
      "Best validation accuracy: 0.9151\n",
      "Associated train accuracy: 0.7966\n",
      "Associated train loss: 0.4688\n",
      "\n",
      "ITERATION 5\n",
      "model: nasnetalarge, batch_size: 24, epochs: 30\n",
      "adam_lr: 0.04753880536405214, adam_b1: 0.8306859829443511, adam_b2: 0.9980061056567583, adam_wtdecay: 0.6136448207940522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 12 epochs.\n",
      "Training completed in 27m 57s\n",
      "Best validation accuracy: 0.9151\n",
      "Associated train accuracy: 0.8836\n",
      "Associated train loss: 0.2650\n",
      "\n",
      "ITERATION 6\n",
      "model: nasnetalarge, batch_size: 24, epochs: 10\n",
      "adam_lr: 0.001, adam_b1: 0.99, adam_b2: 0.95, adam_wtdecay: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 23m 17s\n",
      "Best validation accuracy: 0.9057\n",
      "Associated train accuracy: 0.8300\n",
      "Associated train loss: 0.3869\n",
      "\n",
      "ITERATION 7\n",
      "model: nasnetalarge, batch_size: 24, epochs: 30\n",
      "adam_lr: 0.09999994426994971, adam_b1: 0.9899996011428103, adam_b2: 0.9500001084332256, adam_wtdecay: 1.3033213180257493e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 6 epochs.\n",
      "Training completed in 13m 54s\n",
      "Best validation accuracy: 0.5660\n",
      "Associated train accuracy: 0.5273\n",
      "Associated train loss: 15.5603\n",
      "\n",
      "ITERATION 8\n",
      "model: nasnetalarge, batch_size: 24, epochs: 10\n",
      "adam_lr: 0.05136965597017945, adam_b1: 0.8778725271586237, adam_b2: 0.9995160401837255, adam_wtdecay: 0.1459817441081373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 23m 17s\n",
      "Best validation accuracy: 0.8962\n",
      "Associated train accuracy: 0.7976\n",
      "Associated train loss: 0.4656\n",
      "\n",
      "ITERATION 9\n",
      "model: nasnetalarge, batch_size: 24, epochs: 10\n",
      "adam_lr: 0.021088830134486092, adam_b1: 0.8743896581382656, adam_b2: 0.9668293970436518, adam_wtdecay: 0.130757910252293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 8 epochs.\n",
      "Training completed in 18m 37s\n",
      "Best validation accuracy: 0.8915\n",
      "Associated train accuracy: 0.8067\n",
      "Associated train loss: 0.4532\n",
      "\n",
      "ITERATION 10\n",
      "model: nasnetalarge, batch_size: 24, epochs: 30\n",
      "adam_lr: 0.023737999541605208, adam_b1: 0.8, adam_b2: 0.9999, adam_wtdecay: 0.8920544028917317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 11 epochs.\n",
      "Training completed in 25m 38s\n",
      "Best validation accuracy: 0.9057\n",
      "Associated train accuracy: 0.8563\n",
      "Associated train loss: 0.3332\n",
      "\n",
      "ITERATION 11\n",
      "model: nasnetalarge, batch_size: 24, epochs: 10\n",
      "adam_lr: 0.1, adam_b1: 0.9545965365505027, adam_b2: 0.9999, adam_wtdecay: 0.5528549107419437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 10 epochs.\n",
      "Training completed in 23m 17s\n",
      "Best validation accuracy: 0.9104\n",
      "Associated train accuracy: 0.8968\n",
      "Associated train loss: 0.2609\n",
      "\n",
      "ITERATION 12\n",
      "model: nasnetalarge, batch_size: 16, epochs: 30\n",
      "adam_lr: 0.009265534484135007, adam_b1: 0.9159860527821262, adam_b2: 0.9817114412568977, adam_wtdecay: 0.3226986450689692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 8 epochs.\n",
      "Training completed in 18m 37s\n",
      "Best validation accuracy: 0.9198\n",
      "Associated train accuracy: 0.8735\n",
      "Associated train loss: 0.2897\n",
      "\n",
      "ITERATION 13\n",
      "model: nasnetalarge, batch_size: 32, epochs: 10\n",
      "adam_lr: 0.0876575215666159, adam_b1: 0.9324736249192926, adam_b2: 0.9677430495238785, adam_wtdecay: 0.13303204556081377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early at 8 epochs.\n",
      "Training completed in 18m 36s\n",
      "Best validation accuracy: 0.7358\n",
      "Associated train accuracy: 0.5992\n",
      "Associated train loss: 0.6975\n",
      "\n",
      "ITERATION 14\n",
      "model: nasnetalarge, batch_size: 32, epochs: 10\n",
      "adam_lr: 0.001, adam_b1: 0.8, adam_b2: 0.9999, adam_wtdecay: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 23m 18s\n",
      "Best validation accuracy: 0.8538\n",
      "Associated train accuracy: 0.8340\n",
      "Associated train loss: 0.4200\n",
      "\n",
      "ITERATION 15\n",
      "model: nasnetalarge, batch_size: 16, epochs: 30\n",
      "adam_lr: 0.1, adam_b1: 0.99, adam_b2: 0.95, adam_wtdecay: 0.5585007693167536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train, best val=0.896226:  66%|██████▌   | 648/988 [01:27<00:45,  7.49images/s]"
     ]
    }
   ],
   "source": [
    "from GPyOpt.methods import BayesianOptimization\n",
    "import subprocess\n",
    "import sys\n",
    "sys.setrecursionlimit(1500)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model_num = i\n",
    "    for data_index, datadir in enumerate(('data/die_vs_all_11', 'data/4_class_11')):\n",
    "        global iteration\n",
    "        iteration = 0  # reset to 0\n",
    "        \n",
    "        DATA_DIR = datadir\n",
    "        print(datadir.upper())\n",
    "        NUM_CLASSES = 2 * (data_index+1)\n",
    "    \n",
    "        try:\n",
    "            problem = BayesianOptimization(\n",
    "                f=f,\n",
    "                domain=domain\n",
    "            )\n",
    "            problem.run_optimization(max_iter=10)\n",
    "            problem.plot_acquisition()\n",
    "            problem.plot_convergence()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('Skipping because', e)\n",
    "#             import traceback\n",
    "#             traceback.print_exc()\n",
    "            continue\n",
    "            \n",
    "        # commit & push only if we can connect to internet\n",
    "        subprocess.check_call(['git', 'add', 'experiments'])\n",
    "        subprocess.check_call(['git', 'commit', '-am', f'Results from {str(models[i]).split()[1]} {datadir}'])\n",
    "        subprocess.check_call(['git', 'push'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = subprocess.check_call([\"spd-say\", \"Your code has finished running\"])\n",
    "_ = subprocess.check_call(['git', 'commit', '-am', \"BO final commit\"])\n",
    "_ = subprocess.check_call(['git', 'push'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = \n",
    "# datasets = ['']\n",
    "\n",
    "# #     ptm.se_resnet50,\n",
    "# #     ptm.se_resnet101,\n",
    "# #     ptm.inceptionresnetv2,\n",
    "# #     ptm.inceptionv4,\n",
    "# #     ptm.vgg16,\n",
    "# #     ptm.vgg19,\n",
    "# #     tvm.resnet101,\n",
    "# #     ptm.senet154,\n",
    "\n",
    "# f'-e final_results -d {dataset} -m se_resnet154 pretrained=\"imagenet\" num_classes=1000 -o Adam lr=0.0074 betas='"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
