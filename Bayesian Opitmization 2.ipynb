{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# whether to commit and push to git after each optimization. intended for long runs\n",
    "PUSH_TO_GIT = True\n",
    "\n",
    "# parent output directory\n",
    "EXPERIMENTS_DIR = os.path.join(\"experiments\", \"bayes_opt_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Optimization and train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITERATIONS = 10     # max iterations for bayesian optimization\n",
    "\n",
    "NUM_TRAIN_EPOCHS = 50   # total number of epochs tot rain for\n",
    "EARLY_STOP = 6          # give up training if validation accuracy doesn't improve after this many epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer to use. Choose by commenting. Supposedly by Wilson et al. 2018, SGD generalizes better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "OPTIMIZERS = (\n",
    "    optim.Adam,\n",
    "    optim.SGD,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to test for BO. All in the list will be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models as tvm\n",
    "import pretrainedmodels as ptm\n",
    "\n",
    "# The models we will test\n",
    "MODELS = (\n",
    "#     ptm.alexnet, # gets maximum recursion limit exceeded exceptions\n",
    "#     se_resnext101_32x4d, # input size doesn't work\n",
    "    ptm.nasnetamobile,\n",
    "    ptm.se_resnet50,\n",
    "    ptm.se_resnet101,\n",
    "    ptm.inceptionresnetv2,\n",
    "    ptm.inceptionv4,\n",
    "    tvm.resnet101,\n",
    "    tvm.resnet152,\n",
    "    ptm.senet154,\n",
    "    ptm.pnasnet5large,  # CUDA out of memory errors. only works batch_size <= 12\n",
    "    ptm.polynet,  # CUDA out of memory. only works batch_size <= 16\n",
    "    ptm.nasnetalarge, # only works batch_size <= 12\n",
    "    ptm.vgg16,\n",
    "    ptm.vgg19,\n",
    ")\n",
    "\n",
    "REQUIRES_SMALL_BATCH = {ptm.pnasnet5large, ptm.polynet, ptm.nasnetalarge}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup: Make sure Jupyter shows all output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show more than one output in cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# display full width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 100% !important; }</style>\"))\n",
    "\n",
    "# plot charts in our notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import subprocess  # for command line control, git\n",
    "import sys\n",
    "sys.setrecursionlimit(3000) # for some reason AlexNet requires more recursive depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import src.utils as utils\n",
    "from src.trainable import Trainable\n",
    "import torch\n",
    "\n",
    "\n",
    "CRITERION = torch.nn.CrossEntropyLoss() # we'll always use CE for the loss function\n",
    " \n",
    "\n",
    "def train(params, is_best=False):\n",
    "    \"\"\"\n",
    "    Set up a trainable and train it using the given parameters.\n",
    "    \"\"\"\n",
    "    global iteration\n",
    "    iteration += 1\n",
    "    print('Iteration', iteration if not is_best else \"BEST\", end=', ')\n",
    "    print(params_to_meta_dict(params))  # print the input\n",
    "    batch_size, lr_factor, optim_params = parse_train_params(params)\n",
    "    \n",
    "    # make an output directory using the dataset name, model name, and BO iteration\n",
    "    outdir = make_outdir_name(\n",
    "        data_dir, \n",
    "        utils.get_model_name(chosen_model), \n",
    "        chosen_optimizer.__name__,\n",
    "        str(iteration) if not is_best else \"BEST\",\n",
    "        prepend=EXPERIMENTS_DIR\n",
    "    )\n",
    "    \n",
    "    # make our data loaders based on the image size\n",
    "    image_size = utils.determine_image_size(utils.get_model_name(chosen_model))\n",
    "    # get_train_val_dataloaders() makes a stratified random partitions of a train and validation set\n",
    "    dataloaders = utils.get_train_val_dataloaders(\n",
    "        datadir=data_dir,\n",
    "        val_proportion=0.15,\n",
    "        image_size=image_size, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    # build our model\n",
    "    model = build_model(chosen_model)\n",
    "    utils.fit_model_last_to_dataset(model, dataloaders['train'].dataset)\n",
    "    # build the optimizer\n",
    "    optimizer = chosen_optimizer(model.parameters(), *optim_params)\n",
    "    # \"ReduceOnPlateau\" is \"dev-decay\" as recommended by Wilson et al. 2018 \n",
    "    # \"The Marginal Value of Adaptive Gradient Methods\"\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max', \n",
    "        factor=lr_factor, \n",
    "        patience=1\n",
    "    )\n",
    "    \n",
    "    trainable = Trainable(dataloaders, model, CRITERION, optimizer, lr_scheduler, outdir=outdir)\n",
    "    early_stop = None if is_best else EARLY_STOP  # only early stop if BO. else if training our best, do the full thing\n",
    "    trainable.train(num_epochs=NUM_TRAIN_EPOCHS, early_stop_limit=early_stop, verbose=False)\n",
    "\n",
    "    return trainable\n",
    "\n",
    "\n",
    "def parse_train_params(params):\n",
    "    \"\"\"\n",
    "    Parses train parameters by converting batch size to an int, and the betas to a tuple for Adam.\n",
    "    \"\"\"\n",
    "    batch_size, lr_factor, optim_params = int(params[0]), params[1], params[2:]\n",
    "    if chosen_optimizer is torch.optim.Adam:  # turn b1 and b2 into a tuple\n",
    "        # NOTE the below indexes are based on purely ADAM_DOMAin\n",
    "        optim_params = (optim_params[0], tuple(optim_params[1:3]), optim_params[3])\n",
    "#         print('OPTIM_PARAMS', optim_params)\n",
    "    return batch_size, lr_factor, optim_params\n",
    "\n",
    "    \n",
    "def build_model(model_fn):\n",
    "    \"\"\"\n",
    "    Build a pretrained model class from a model function. Passes \n",
    "    in the appropriate pretrained arg based on the model function's \n",
    "    parent module.\n",
    "    \"\"\"\n",
    "    if 'pretrainedmodels' in model_fn.__module__:\n",
    "        model = model_fn(num_classes=1000, pretrained='imagenet')\n",
    "    else:\n",
    "        model = model_fn(pretrained=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_key_from_params(params):\n",
    "    \"\"\"\n",
    "    Makes a unique key (as a tuple) from a given list of parameters.\n",
    "    For storing associated Trainable objects.\n",
    "    \n",
    "    \"\"\"\n",
    "    return tuple(round(param, 10) for param in params)\n",
    "\n",
    "\n",
    "def make_outdir_name(data_dir, *append, prepend=\"\"):\n",
    "    \"\"\"\n",
    "    Make the output directory name based on dataset, model name, and any extra info.\n",
    "    \"\"\"\n",
    "    dataset_name = os.path.basename(data_dir)\n",
    "    return os.path.join(prepend, dataset_name, *append) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript\n",
    "\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "def save_notebook():\n",
    "    \"\"\"Save the Jupyter notebook\"\"\"\n",
    "    Javascript(script)\n",
    "\n",
    "def push_to_git(message=\"Commit\"):\n",
    "    save_notebook()\n",
    "    try:\n",
    "        _ = subprocess.check_call(['git', 'add', '-u'])\n",
    "        _ = subprocess.check_call(['git', 'add', EXPERIMENTS_DIR])\n",
    "        _ = subprocess.check_call(['git', 'commit', '-am', message])\n",
    "        _ = subprocess.check_call(['git', 'push'])\n",
    "    except Error as e:\n",
    "        print(\"ERROR: Could not push to git.\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SMALL_BATCH = (1, 4, 8, 12)\n",
    "MEDIUM_BATCH = (16, 24, 32, 48, 64)\n",
    "\n",
    "BASE_DOMAIN = [\n",
    "#     {'name': 'batch_size', 'type': 'discrete', 'domain': (1, 4, 8, 12)},  # DEBUG for GPUs with insufficient memory\n",
    "    {'name': 'batch_size', 'type': 'discrete', 'domain': MEDIUM_BATCH},\n",
    "    {'name': 'lr_decay', 'type': 'continuous', 'domain': (0.03, 0.3)},\n",
    "]\n",
    "\n",
    "ADAM_DOMAIN = BASE_DOMAIN + [\n",
    "    {'name': 'adam_lr', 'type': 'continuous', 'domain': (0.001, 0.1)},\n",
    "    {'name': 'adam_beta1', 'type': 'continuous', 'domain': (0.8, .99)},\n",
    "    {'name': 'adam_beta2', 'type': 'continuous', 'domain': (0.95, .9999)},\n",
    "    {'name': 'adam_wtdecay', 'type': 'continuous', 'domain': (0, 1)}\n",
    "]\n",
    "# TODO: have to figure out how to set a starting default\n",
    "# default_input = [32, 0.001, 0.9, 0.999, 0] \n",
    "\n",
    "SGD_DOMAIN = BASE_DOMAIN + [\n",
    "    {'name': 'lr', 'type': 'continuous', 'domain': (0.001, 0.1)},\n",
    "    {'name': 'momentum', 'type': 'continuous', 'domain': (0.5, .99)},\n",
    "    {'name': 'weight_decay', 'type': 'continuous', 'domain': (0, 1)}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\" Value function to maximize for bayesian optimization \"\"\"\n",
    "    params = x.flatten()\n",
    "#     print('PARAMS', params)\n",
    "    \n",
    "    trainable = train(params)\n",
    "    val_acc = trainable.best_val_accuracy\n",
    "    \n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do BO on all models on both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPyOpt.methods import BayesianOptimization\n",
    "from predict import create_predictions\n",
    "from metrics import create_all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_globals(datadir):\n",
    "    \"\"\"\n",
    "    Reset the iteration and set the data directory\n",
    "    \"\"\"\n",
    "    global iteration  # keep track of our optimization iterations for directory output\n",
    "    iteration = 0   # but reset to 0 each train run\n",
    "    global data_dir\n",
    "    data_dir = datadir\n",
    "    \n",
    "\n",
    "def get_domain():\n",
    "    \"\"\"\n",
    "    Get the domain parameters given the chosen optimizer\n",
    "    \"\"\"\n",
    "    domain = ADAM_DOMAIN if chosen_optimizer is torch.optim.Adam else SGD_DOMAIN\n",
    "    # some models are too big to fit on our NVIDIA Quadro P5000 GPU. if the\n",
    "    # chosen model is on eof these, decrease the batch size\n",
    "    if chosen_model in REQUIRES_SMALL_BATCH:\n",
    "        domain[0]['domain'] = SMALL_BATCH  # domain[0] is batch_size\n",
    "        \n",
    "    return domain\n",
    "    \n",
    "def perform_bayesian_optimization():\n",
    "    \"\"\"\n",
    "    Construct the problem and run the optimization.\n",
    "    \"\"\"\n",
    "    domain = get_domain()\n",
    "    problem = BayesianOptimization(\n",
    "        f=f,\n",
    "        domain=domain,\n",
    "        maximize=True\n",
    "    )\n",
    "    problem.run_optimization(max_iter=MAX_ITERATIONS)\n",
    "    return problem\n",
    "\n",
    "def plot_bo_results(problem):\n",
    "    \"\"\"\n",
    "    Graph the acquisition function and convergence\n",
    "    \"\"\"\n",
    "    print('Best params:', problem.x_opt)\n",
    "    problem.plot_acquisition()\n",
    "    problem.plot_convergence()\n",
    "    \n",
    "    \n",
    "def params_to_meta_dict(params):\n",
    "    \"\"\"\n",
    "    Takes a list and returns a dictionary of named parameters based on domain index\n",
    "    \"\"\"\n",
    "    domain = get_domain()\n",
    "    meta = { d['name']: float(params[i]) for i, d in enumerate(domain)}\n",
    "    return meta\n",
    "\n",
    "\n",
    "def generate_test_metrics(trainable):\n",
    "    \"\"\"\n",
    "    Create an itemized predictions file and metrics for the test set.\n",
    "    \"\"\"\n",
    "    predictions_file = create_predictions(\n",
    "        outdir=trainable.outdir,\n",
    "        subset='test',\n",
    "        data_dir=data_dir,\n",
    "        model=best_trainable.model\n",
    "    )\n",
    "    create_all_metrics(predictions_file, trainable.outdir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasnetamobile SGD data/die_vs_all_tt\n",
      "Iteration 1, {'batch_size': 64.0, 'lr_decay': 0.21455954253192575, 'lr': 0.047519849797456666, 'momentum': 0.8491312480494226, 'weight_decay': 0.010770390859161427}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.8111; Associated train accuracy: 0.8301\n",
      "Iteration 2, {'batch_size': 16.0, 'lr_decay': 0.2647940187549423, 'lr': 0.06492498684481082, 'momentum': 0.5051239025498285, 'weight_decay': 0.04225285121210165}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train, best val=0.0000:   6%|▋         | 64/1018 [00:01<00:34, 27.86images/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigint caught!\n",
      "Training will stop after this epoch and the best model so far will be saved.\n",
      "OR press Ctrl-C again to quit immediately without saving.Sigint caught!\n",
      "Training will stop after this epoch and the best model so far will be saved.\n",
      "OR press Ctrl-C again to quit immediately without saving.\n",
      "\n",
      "Sigint caught!\n",
      "Training will stop after this epoch and the best model so far will be saved.\n",
      "OR press Ctrl-C again to quit immediately without saving.Sigint caught!\n",
      "Training will stop after this epoch and the best model so far will be saved.\n",
      "OR press Ctrl-C again to quit immediately without saving.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1, Train, best val=0.0000:   8%|▊         | 80/1018 [00:02<00:29, 31.60images/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping...\n",
      "Stopping...\n",
      "Stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping...\n",
      "Sigint caught!\n",
      "Training will stop after this epoch and the best model so far will be saved.\n",
      "OR press Ctrl-C again to quit immediately without saving.\n",
      "Stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/alwood/anaconda3/envs/eai/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2969: UserWarning:To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "import gc # for manual garbage collection, reduce memory consumption\n",
    "\n",
    "for chosen_model in MODELS:  # iterate over all models\n",
    "    for chosen_optimizer in OPTIMIZERS: # iterate over all optimizers\n",
    "\n",
    "        # iterate over both binary and quaternary datasets\n",
    "        for data_dir in (\n",
    "            os.path.join('data', 'die_vs_all_tt'), \n",
    "            os.path.join('data', '4_class_tt')\n",
    "        ):\n",
    "            print(utils.get_model_name(chosen_model), chosen_optimizer.__name__, data_dir)\n",
    "            reset_globals(data_dir)  # reset some globals used for iteration tracking\n",
    "\n",
    "            commit_message = f'Results for {data_dir} {utils.get_model_name(chosen_model)} {chosen_optimizer.__name__}.'\n",
    "            try:\n",
    "                # define and optimize the problem\n",
    "                optimized = perform_bayesian_optimization()\n",
    "                # plot the results\n",
    "                plot_bo_results(optimized)\n",
    "                # get and save the best trainable\n",
    "                best_params = optimized.x_opt.flatten()\n",
    "                print('Best params:', (params_to_meta_dict(best_params)))\n",
    "                best_trainable = train(best_params, is_best=True)\n",
    "                best_trainable.save(extra_meta=params_to_meta_dict(best_params))\n",
    "                # evalute on the test set using the best model\n",
    "                generate_test_metrics(best_trainable)\n",
    "                commit_message += f' Best val: {best_trainable.best_val_accuracy:.4f}; Train: {best_trainable.associated_train_accuracy:.4f}'\n",
    "                \n",
    "            # if something bad happens, skip it so we can let the others run\n",
    "            except Exception as e:\n",
    "                print('Skipping because', e)\n",
    "                _ = subprocess.check_call([\"spd-say\", \"Uh-oh, something bad happened. \"])\n",
    "                _ = subprocess.check_call([\"spd-say\", f'{utils.get_model_name(chosen_model)}. {str(e).split()[:4]}.'])\n",
    "                    \n",
    "                import traceback  # DEBUG\n",
    "                traceback.print_exc()\n",
    "                commit_message += f' EXCEPTION {e}.'\n",
    "    \n",
    "            gc.collect()  # reduce memory usage\n",
    "\n",
    "            # commit & push\n",
    "            if PUSH_TO_GIT:\n",
    "                \n",
    "                push_to_git(commit_message)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Commit and Push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PUSH_TO_GIT:\n",
    "    import time\n",
    "    time.sleep(120) # wait for two minutes to let everything render\n",
    "    _ = subprocess.check_call([\"spd-say\", \"Your code has finished running\"])\n",
    "    push_to_git(\"BO Final Commit\")\n",
    "    \n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
