{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In delgado et al., the best performing models were Linear kernel SVM and MLP for both binary and quaternary classification\n",
    "\n",
    "Performed grid hyperparameter search\n",
    "and 5-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical ML Experiments I want to do:\n",
    "\n",
    "\n",
    "Bayesian Optimize all\n",
    "\n",
    "Binary classification:\n",
    "- diestrus vs rest\n",
    "- pro-est vs met-die\n",
    "\n",
    "Quaternary classification\n",
    "\n",
    "LinearSVC\n",
    "\n",
    "MLP, architectural search\n",
    "\n",
    "W/out GAN augmented, with GAN Augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Caution:\n",
    "We should only use GAN data to augment train, not on validaiton set.\n",
    "What if we train on GAN data but then don't have GAN data in our validation. How will it perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC is O(N^2)\n",
    "https://datascience.stackexchange.com/a/996\n",
    "\n",
    "Note: because SVC computation time is O(n^2), doing hyperparameter search for SVM will take muchhh too long. For 25 bayes-opt cross-validation iterations, averaging at 780s/it, is over 5 hours. I have 6 sets that I wish to evaluate for SVC. 30 hours running non-stop is too much.\n",
    "\n",
    "Might want to solve this with bagging\n",
    "\n",
    "We might run just 1 solitary of the best bagged version SVC to compare, instead of running 6 combos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.miniconda3/envs/pt/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import skopt\n",
    "import pandas as pd\n",
    "import os\n",
    "import errno\n",
    "import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup output directories\n",
    "\n",
    "The below box will ask you to confirm if you intend to create a folder to run a new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No experiment name chosen. What do you want to name this experiment? (Leave blank for current date)\n",
      "EXPERIMENT_NAME: optimize_and_test\n",
      "Are you sure you want to make a new experiment at ../experiments/delgado/optimize_and_test? (y/N): y\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"fix_norm_and_eval_test\" # None\n",
    "\n",
    "root = \"../experiments/delgado/\"\n",
    "DATE_FMT = \"%Y-%m-%d_%H-%M_%S\"\n",
    "\n",
    "if not EXPERIMENT_NAME:\n",
    "    a = input(\n",
    "        \"No experiment name chosen. What do you want to name this experiment? (Leave blank for current date)\"\n",
    "        \"\\nEXPERIMENT_NAME: \"\n",
    "    )\n",
    "    a = a.strip().replace(\" \", \"_\")\n",
    "    EXPERIMENT_NAME = a if len(a) > 0 else datetime.now().strftime(DATE_FMT)\n",
    "\n",
    "OUT_DIR = root + EXPERIMENT_NAME\n",
    "\n",
    "def create_folders():\n",
    "    a = \"y\"# input(\"Are you sure you want to make a new experiment at \" + OUT_DIR + \"? (y/N): \")\n",
    "    if a.lower().strip() != \"y\":\n",
    "        assert False, \"User chose not to make a new experiment.\"\n",
    "\n",
    "    try:\n",
    "        os.makedirs(OUT_DIR)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST:\n",
    "            c = \"y\" # input(f\"The path {OUT_DIR} already exists. Are you sure you want to continue? (y/N): \")\n",
    "            if c.lower().strip() != \"y\":\n",
    "                assert False, \"User chose not to continue\"\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "create_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/gan_augmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32640"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_DIR + \"/train.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14376"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_gan = df[df[\"file\"].str.startswith(\"gan_\")==False]\n",
    "len(no_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_only = df[df[\"file\"].str.startswith(\"gan_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    \"BASE\": {\n",
    "        \"X\": no_gan.drop(columns=[\"file\", \"label\", \"patch_num\"]),\n",
    "        \"y\": no_gan[\"label\"]\n",
    "    },\n",
    "    \"AUGMENT\": {\n",
    "        \"X_augment\": gan_only.drop(columns=[\"file\", \"label\", \"patch_num\"]),\n",
    "        \"y_augment\": gan_only[\"label\"]\n",
    "    }\n",
    "}\n",
    "DATASETS[\"AUGMENT\"].update(DATASETS[\"BASE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diestrus     1608\n",
       "estrus        432\n",
       "proestrus     408\n",
       "metestrus     276\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(DATA_DIR + \"/test.csv\")\n",
    "X_test = test_df.drop(columns=[\"file\", \"label\", \"patch_num\"])\n",
    "y_test = test_df[\"label\"]\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "             with_scaling=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def apply_scaler(*args):\n",
    "    return [scaler.transform(a) for a in args]\n",
    "\n",
    "scaler = RobustScaler().fit(DATASETS[\"BASE\"][\"X\"])\n",
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Define desired models. Add more if desired\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MAX_N_HIDDEN = 5\n",
    "\n",
    "DESIRED_MODELS = {\n",
    "#     \"LinearSVC\": {\n",
    "#         \"model\": LinearSVC,\n",
    "#         \"space\": [\n",
    "#             Real(1, 10**6, prior=\"log-uniform\", name=\"C\"),\n",
    "#             Categorical((\"balanced\", None), name=\"class_weight\")\n",
    "#         ]\n",
    "#     },\n",
    "#     \"CrammerSingerLinearSVC\": {\n",
    "#         \"model\": LinearSVC,\n",
    "#         \"space\": [\n",
    "#             Real(1, 10**6, prior=\"log-uniform\", name=\"C\"),\n",
    "#             Categorical((\"balanced\", None), name=\"class_weight\"),\n",
    "#             Categorical((\"crammer_singer\",), name=\"multi_class\")\n",
    "#         ]\n",
    "#     },\n",
    "    \"RBFSVC\": {\n",
    "        \"model\": SVC,\n",
    "        \"space\": [\n",
    "            Real(1e2, 1e4, prior=\"log-uniform\", name=\"C\"),\n",
    "            Categorical((\"balanced\", None), name=\"class_weight\"),\n",
    "            Categorical((\"rbf\",), name=\"kernel\"),\n",
    "            Real(1e-2,  10, prior=\"log-uniform\", name=\"gamma\"),\n",
    "        ]\n",
    "    },\n",
    "    \"PolySVC\": {\n",
    "        \"model\": SVC,\n",
    "        \"space\": [\n",
    "            Real(1, 10**6, prior=\"log-uniform\", name=\"C\"),\n",
    "            Categorical((\"balanced\", None), name=\"class_weight\"),\n",
    "            Categorical((\"poly\",), name=\"kernel\"),\n",
    "            Real(1e-2,  10, prior=\"log-uniform\", name=\"gamma\"),\n",
    "        ]\n",
    "    },\n",
    "#     \"MLP\": {\n",
    "#         \"model\": MLPClassifier,\n",
    "#         \"space\": [\n",
    "#             Real(0.001, 1.0, prior=\"log-uniform\", name=\"learning_rate_init\"),\n",
    "#         ] + [Integer(0, 150, name=f\"n_layer_{i}\") for i in range(MAX_N_HIDDEN)] # add on hidden\n",
    "#     },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose class groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regroup_classes(y, *classes):\n",
    "    \"\"\"\n",
    "    Regroup class labels\n",
    "    \n",
    "    Args\n",
    "        y: a Pandas series\n",
    "        *classes: tuple grouping classes together. E.g. (\"proestrus\", \"estrus\")\n",
    "    \"\"\"\n",
    "    for group in classes:\n",
    "        if type(group) is tuple or type(group) is list:\n",
    "            combined_name = \"_\".join(group)\n",
    "            for g in group:\n",
    "                y = y.replace(g, combined_name)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIRED_CLASS_GROUPS = {\n",
    "    \"4-way\": (\"proestrus\", \"estrus\", \"metestrus\", \"diestrus\"),     # 4-way\n",
    "    \"binary_pe-v-md\": ((\"proestrus\", \"estrus\"), (\"metestrus\", \"diestrus\")), # binary v1\n",
    "    \"binary_pem-v-d\": ((\"proestrus\", \"estrus\", \"metestrus\"), (\"diestrus\")), # binary v2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Optimization Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvalidModelException(Exception):\n",
    "    pass\n",
    "\n",
    "def fix_params(mname, params):\n",
    "    # MLP needs to replace hidden layers parameters\n",
    "    if mname is \"MLP\":\n",
    "        params = replace_mlp_params(params)\n",
    "        # case: tries to set all to 0, then no reward\n",
    "        if \"hidden_layer_sizes\" not in params or not np.any(params[\"hidden_layer_sizes\"]):\n",
    "            raise InvalidModelException(\"MLP missing valid hidden_layer_sizes\")\n",
    "    elif \"SVC\" in mname:\n",
    "        params[\"max_iter\"] = -1\n",
    "\n",
    "def replace_mlp_params(params):\n",
    "    \"\"\"\n",
    "    Replaces the bayes-opt params with actual params for sklearn's MLPClassifier.\n",
    "    \n",
    "    Had to do this hacky thing to get bayes opt to simultaneously search for \n",
    "    number of layers and number of neurons per layer.\n",
    "    Because sklearn takes an array of >0 layer sizes to initialize hidden layers.\n",
    "    \"\"\"\n",
    "    # create hidden layer if greater than zero\n",
    "    hidden_layer_sizes = [\n",
    "        params[f\"n_layer_{i}\"] for i in range(MAX_N_HIDDEN) \n",
    "        if f\"n_layer_{i}\" in params and params[f\"n_layer_{i}\"] > 0\n",
    "    ]\n",
    "    if len(hidden_layer_sizes) > 0:\n",
    "        params[\"hidden_layer_sizes\"] = hidden_layer_sizes\n",
    "    # get rid of the dummy params\n",
    "    [params.pop(f\"n_layer_{i}\") for i in range(MAX_N_HIDDEN) if f\"n_layer_{i}\" in params]\n",
    "    return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_numpy(*args):\n",
    "    return [a.values if a is not None else a for a in args ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils._joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def my_cross_validate(model, X, y, X_augment=None, y_augment=None, cv=5, n_jobs=1):\n",
    "    \"\"\"\n",
    "    A cross validation function with the option to augment the training data after the split.\n",
    "    WARNING: does not support parallel operation\n",
    "    \"\"\"\n",
    "    # convert from pandas df to numpy arrays, because KFold indexes for numpy\n",
    "    X, y, X_augment, y_augment = pandas_to_numpy(X, y, X_augment, y_augment)\n",
    "    # split the data    \n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    splits = skf.split(X, y)\n",
    "    # run parallel jobs to run splits faster\n",
    "    parallel = Parallel(n_jobs=n_jobs)\n",
    "    scores = parallel(\n",
    "        delayed(split_augment_score)(\n",
    "            clone(model), train_index, val_index, X, y, X_augment, y_augment\n",
    "        )\n",
    "        for train_index, val_index in splits\n",
    "    )   \n",
    "    return scores\n",
    "\n",
    "def split_augment_score(model, train_index, val_index, X, y, X_augment=None, y_augment=None):\n",
    "    \"\"\" \n",
    "    Helper function for my_cross_validate\n",
    "    Selects the data at the given split. \n",
    "    If X_augment and y_augment are provided, it augments the training data AFTER the split.\n",
    "    Then fits and scores the model.\n",
    "    \"\"\"\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_train, y_train = maybe_augment(X_train, y_train, X_augment, y_augment)\n",
    "    \n",
    "    X_val, y_val = X[val_index], y[val_index]\n",
    "    # normalize\n",
    "    X_train, X_val = apply_scaler(X_train, X_val)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_val, y_val)\n",
    "\n",
    "\n",
    "def maybe_augment(X_train, y_train, X_augment, y_augment):\n",
    "    \"\"\"\n",
    "    Append augmented to X_train and y_train if not None\n",
    "    \"\"\"\n",
    "    if X_augment is not None and y_augment is not None:\n",
    "        X_train = np.append(X_train, X_augment, axis=0)\n",
    "        y_train = np.append(y_train, y_augment, axis=0)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if len(completed) > 0:\n",
    "        ans = input(\"(!) WARNING: Are you sure you want to run this box?\"\n",
    "                    f\"completed={completed}\"\n",
    "                    \"The current value of completed will be overwritten. (y/N): \")\n",
    "        if ans != \"y\":\n",
    "            assert False, \"User chose keep completed progress.\"\n",
    "except NameError:\n",
    "    # keep track of completed runs in this session so we don't have to rerun\n",
    "    completed = [\n",
    "    #     (\"MLP\", \"AUGMENT\", \"binary_pe-v-md\"), # example\n",
    "    ]\n",
    "finally:\n",
    "    print(\"Completed:\\n\",completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def copy_and_regroup(data, class_groups=None):\n",
    "    \"\"\"\n",
    "    Creates a deep copy of the data dictionary and regroups class labels.\n",
    "    \"\"\"\n",
    "    datacopy = copy.deepcopy(data)\n",
    "    if class_groups:\n",
    "        datacopy[\"y\"] = regroup_classes(datacopy[\"y\"], *class_groups)\n",
    "        if \"y_augment\" in datacopy:\n",
    "            datacopy[\"y_augment\"] = regroup_classes(datacopy[\"y_augment\"], *class_groups)                        \n",
    "        \n",
    "    return datacopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(cls, params):\n",
    "    model = cls(**params)\n",
    "    # change SVC to bagging to signficantly reduce train time, and even improve accuracy\n",
    "    # https://stackoverflow.com/a/32025662/5118517\n",
    "    if \"SVC\" in type(model).__name__:\n",
    "        n_est = 10\n",
    "        model = OneVsRestClassifier(\n",
    "            BaggingClassifier(model, n_estimators=n_est, max_samples=1/n_est)\n",
    "            #, n_jobs=-1\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "NUM_POINTS = 25 \n",
    "\n",
    "K_FOLDS = 5\n",
    "\n",
    "def run_optimization(\n",
    "    desired_models=DESIRED_MODELS, \n",
    "    desired_datasets=DATASETS, \n",
    "    desired_class_groups=DESIRED_CLASS_GROUPS\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs bayesian optimization on all combinations of the desired parameters.\n",
    "    \"\"\"\n",
    "    for mname, model_params in tqdm(desired_models.items()):\n",
    "        # comment: I put in sorted here because kept crashing on the Augmented dataset. wanted to run it first to check\n",
    "        for dname, data in tqdm(sorted(desired_datasets.items()), leave=False):\n",
    "            for gname, class_groups in tqdm(desired_class_groups.items(), leave=False):\n",
    "                # set up resume optimization loop\n",
    "                this_run = (mname, dname, gname)\n",
    "                if this_run in completed:\n",
    "                    print(\"Skipping\", this_run, end=\"; \")\n",
    "                    continue\n",
    "                print(\"\\n=====\", this_run, \"=====\")\n",
    "                time_start = datetime.now() # record start time\n",
    "                \n",
    "                # regroup class labels, e.g. combine proestrus and estrus into one class.\n",
    "                datacopy = copy_and_regroup(data, class_groups)\n",
    "                global y_test\n",
    "                y_test_regroup = regroup_classes(y_test, *class_groups)\n",
    "                print(\"class groups:\", datacopy[\"y\"].unique())\n",
    "\n",
    "                # skopt decorator, fill in params named spaces defined above\n",
    "                space = model_params[\"space\"]\n",
    "                # define the minimizing objective function\n",
    "                @use_named_args(space)\n",
    "                def objective(**params):\n",
    "                    try:\n",
    "                        fix_params(mname, params)\n",
    "                    except InvalidModelException:\n",
    "                        return 0\n",
    "                    # instantiate the model\n",
    "                    model = init_model(model_params[\"model\"], params)\n",
    "                    score = -np.mean(my_cross_validate(model, cv=K_FOLDS, n_jobs=-1, **datacopy))\n",
    "                    \n",
    "                    return score\n",
    "                # run bayes opt\n",
    "                results_gp = gp_minimize(\n",
    "                    objective, space, n_calls=NUM_POINTS, random_state=0, verbose=True\n",
    "                )\n",
    "                time_end = datetime.now() # record end time\n",
    "                \n",
    "                train_score, test_score, best_model = train_and_test(\n",
    "                    model_params[\"model\"], params, X_test, y_test_regroup, **datacopy\n",
    "                )\n",
    "                # save results\n",
    "                save_results(\n",
    "                    model_name=mname, \n",
    "                    data_name=dname, \n",
    "                    gname=gname, \n",
    "                    class_groups=datacopy[\"y\"].unique(), \n",
    "                    space=space, \n",
    "                    results_gp=results_gp, \n",
    "                    time_start=time_start, \n",
    "                    time_end=time_end,\n",
    "                    best_train=train_score,\n",
    "                    best_test=test_score,\n",
    "                )\n",
    "                save_model(best_model, mname, dname, gname)\n",
    "                completed.append(this_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model_class, params, X_test, y_test, X_train, y_train, X_augment=None, y_augment=None):\n",
    "    X_train, y_train, X_augment, y_augment = pandas_to_numpy(X_train, y_train, X_augment, y_augment)\n",
    "    X_train, y_train = maybe_augment(X_train, y_train, X_augment, y_augment)\n",
    "    \n",
    "    X_train, X_test = apply_scaler(X_train, X_test) # normalize\n",
    "    \n",
    "    model = init_model(model_class, params)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    \n",
    "    return train_score, test_score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_parameters(space, results_gp):\n",
    "    return {space[i].name: str(value) for i, value in enumerate(results_gp.x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from skopt.plots import plot_convergence\n",
    "from joblib import dump, load\n",
    "\n",
    "def save_model(model, model_name, data_name, gname):\n",
    "    fname = \"_\".join((gname, data_name, model_name, \"BEST\"))\n",
    "    path = os.path.join(OUT_DIR, fname)\n",
    "    dump(model, path + \".joblib\")    \n",
    "    \n",
    "def save_results(\n",
    "    model_name, \n",
    "    data_name, \n",
    "    gname, \n",
    "    class_groups, \n",
    "    space, \n",
    "    results_gp, \n",
    "    time_start, \n",
    "    time_end,\n",
    "    best_train,\n",
    "    best_test\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves the results from bayesian optimization. Saves: info, results object, and convergence plot.\n",
    "    \"\"\"\n",
    "    fname = \"_\".join((gname, data_name, model_name))\n",
    "    path = os.path.join(OUT_DIR, fname)\n",
    "\n",
    "    # save run info\n",
    "    info = {\n",
    "        \"time_start\": time_start.strftime(DATE_FMT),\n",
    "        \"time_end\": time_end.strftime(DATE_FMT),\n",
    "        \"duration\": str(time_end - time_start),\n",
    "        \"model\": model_name,\n",
    "        \"dataset\": data_name,\n",
    "        \"class_groups\": str(sorted(class_groups)),\n",
    "        \"space\": str(space),\n",
    "        \"best_validation\": str(-results_gp.fun) # add negative because this gp minimizes, flip back to positive\n",
    "    }\n",
    "    best_parameters = get_best_parameters(space, results_gp)\n",
    "    info[\"best_parameters\"] = best_parameters\n",
    "    info[\"best_train\"] = best_train\n",
    "    info[\"best_test\"] = best_test\n",
    "    \n",
    "    with open(path + \".json\", \"w\") as f:\n",
    "        json.dump(info, f, indent=4)\n",
    "        \n",
    "    # pickle the result itself\n",
    "    skopt.dump(results_gp, path + \".pkl\", store_objective=False, compress=3)\n",
    "    \n",
    "    # save convergence plot\n",
    "    plt.close() # close any figures first, prevent overlapping figures\n",
    "    plot_convergence(results_gp).figure.savefig(path + \"_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a32ccc3d8e4c21a2d6cdfe3ca76957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3516c7feaf2948459dcea6b44e433c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98aa95fa191465e8c40683a85595a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ('RBFSVC', 'AUGMENT', '4-way') =====\n",
      "class groups: ['diestrus' 'estrus' 'metestrus' 'proestrus']\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 102.7336\n",
      "Function value obtained: -0.1259\n",
      "Current minimum: -0.1259\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 19.7433\n",
      "Function value obtained: -0.7334\n",
      "Current minimum: -0.7334\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 75.9700\n",
      "Function value obtained: -0.6795\n",
      "Current minimum: -0.7334\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 98.2025\n",
      "Function value obtained: -0.4455\n",
      "Current minimum: -0.7334\n",
      "Iteration No: 5 started. Evaluating function at random point.\n"
     ]
    }
   ],
   "source": [
    "run_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
